{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ad1459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "import os\n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b9a8a8cbafe85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stockfish import Stockfish\n",
    "# from llama_cpp import Llama\n",
    "\n",
    "# # Set paths\n",
    "# # Initialize Stockfish\n",
    "# stockfish = Stockfish(STOCKFISH_PATH)\n",
    "# stockfish.set_skill_level(20)  # Max strength\n",
    "\n",
    "# # Initialize Llama model\n",
    "# llm = Llama(model_path=LLAMA_MODEL_PATH)\n",
    "\n",
    "# def get_best_move(fen):\n",
    "#     \"\"\"Get the best move from Stockfish.\"\"\"\n",
    "#     stockfish.set_fen_position(fen)\n",
    "#     return stockfish.get_best_move()\n",
    "\n",
    "# def explain_move(fen):\n",
    "#     \"\"\"Use Llama to explain the move.\"\"\"\n",
    "#     move = get_best_move(fen)\n",
    "#     #prompt = f\"You are a chess coach. Explain why '{move}' is a best move in this position: {fen}.You have to tell the children everything or else they would never understand the things clearly , try to be a bit jolly.\"\n",
    "#     prompt=f\"Hello,World\"\n",
    "#     output = llm(prompt, max_tokens=100, stop=[\"\\n\"])\n",
    "#     return move, output[\"choices\"][0][\"text\"]\n",
    "\n",
    "# # Example usage\n",
    "# fen = \"r1bqk2r/pppp1ppp/2n2n2/2b1p3/2B1P3/2N2N2/PPPP1PPP/R1BQ1RK1 b kq - 7 5\"  # Example FEN position\n",
    "# move, explanation = explain_move(fen)\n",
    "\n",
    "# print(f\"Best Move: {move}\")\n",
    "# print(f\"Explanation: {explanation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c58140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()  # Load variables from .env\n",
    "api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "STOCKFISH_PATH=os.environ.get(\"STOCKFISH_PATH\")\n",
    "LLAMA_MODEL_PATH=os.environ.get(\"LLAMA_MODEL_PATH\")\n",
    "print(api_key)  # Verify if it's loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97649270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(response):\n",
    "    response=re.sub(r'<think>.*?</think>','',response,flags=re.DOTALL)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b21b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The best move for Black in the given position is to castle kingside, moving the king from e8 to g8 and the rook from h8 to f8. This move, denoted as O-O, is optimal for several strategic reasons:\n",
      "\n",
      "1. **King Safety]:** The king is currently on e8, which is somewhat exposed with an empty e7 square. Castling moves the king to g8, placing it behind the pawns on f7 and g7, enhancing its protection.\n",
      "\n",
      "2. **Rook Activation:** After castling, the rook moves to f8, connecting both rooks and enabling them to work together in defending the position or supporting potential attacks.\n",
      "\n",
      "3. **Prophylactic Measure:** This move is a preventive strategy to prevent potential threats from White's pieces, such as the bishop on b5 and the pawn on d5, which could otherwise target the king.\n",
      "\n",
      "4. **Flexibility:** Castling kingside does not commit Black to a specific pawn structure, allowing flexibility in responding to future developments by White.\n",
      "\n",
      "By castling kingside, Black secures their king, connects their rooks, and prepares for a more coordinated defense or potential counterplay.\n"
     ]
    }
   ],
   "source": [
    "client = Groq(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a chess coach , explain it well as if you thought of it\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Justify why casteling e8g8 is the best movie for the FEN r1bqk2r/pppp1ppp/2n2n2/2b1p3/2B1P3/2N2N2/PPPP1PPP/R1BQ1RK1 b kq - 7 5\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"deepseek-r1-distill-llama-70b\",\n",
    ")\n",
    "\n",
    "print(clean(chat_completion.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa265867",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BasicChatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
