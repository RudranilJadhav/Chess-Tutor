{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad1459f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from groq import Groq\n",
    "from stockfish import Stockfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97c58140",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # Load variables from .env\n",
    "STOCKFISH_PATH=os.environ.get(\"STOCKFISH_PATH\")\n",
    "LLAMA_MODEL_PATH=os.environ.get(\"LLAMA_MODEL_PATH\")\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")\n",
    "stockfish = Stockfish(STOCKFISH_PATH,depth=25,parameters={\"Threads\": 20,\"Minimum Thinking Time\": 10})\n",
    "d1=pd.read_csv('theory/a.tsv', sep='\\t', header=0)\n",
    "d2=pd.read_csv('theory/b.tsv', sep='\\t', header=0)\n",
    "d3=pd.read_csv('theory/c.tsv', sep='\\t', header=0)\n",
    "d4=pd.read_csv('theory/d.tsv', sep='\\t', header=0)\n",
    "d5=pd.read_csv('theory/e.tsv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97649270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(response):\n",
    "    response=re.sub(r'<think>.*?</think>','',response,flags=re.DOTALL)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c282fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_move(fen):\n",
    "    stockfish.set_fen_position(fen)\n",
    "    return stockfish.get_best_move()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b21b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ch_comp_bm_w_exp(fen,best_move,type_of_move,evaluation):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a top-tier chess coach with deep strategic and tactical mastery. Your task is to recommend the best move with absolute clarity, using proper chess notation and piece names. Justify the move with precise reasoningâ€”covering positional, tactical, and strategic factors. Highlight threats, weaknesses, and long-term plans. Keep explanations concise, potent, and highly structured to maximize the user's chess understanding.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Justify why {type_of_move} {best_move} is the best move for the FEN {fen} with an evaluation of {evaluation}\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"deepseek-r1-distill-llama-70b\",\n",
    "    )\n",
    "\n",
    "    return clean(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b582c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ch_comp_th(eco,name,pgn):\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"You are a chess coach , explain a theory behind the opening of the move with the name {name} ,ECO {eco} and the PGN {pgn} , please tell ALL THE pros and cons of the opening . All the variations and how to play against them.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Explain the pros and cons and how to play against the best variations of the opening of the name {name} ,ECO {eco} and the PGN {pgn}\",\n",
    "            }\n",
    "        ],\n",
    "        model=\"deepseek-r1-distill-llama-70b\",\n",
    "    )\n",
    "\n",
    "    return clean(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5d9aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(theory):\n",
    "    for x in range(0,len(d1[\"name\"])):\n",
    "        if d1[\"name\"][x].lower()==theory.lower():\n",
    "            return d1['eco'][x],d1['name'][x],d1['pgn'][x]\n",
    "    for x in range(0,len(d2[\"name\"])):\n",
    "        if d2[\"name\"][x].lower()==theory.lower():\n",
    "            return d2['eco'][x],d2['name'][x],d2['pgn'][x]\n",
    "    for x in range(0,len(d3[\"name\"])):\n",
    "        if d3[\"name\"][x].lower()==theory.lower():\n",
    "            return d3['eco'][x],d3['name'][x],d3['pgn'][x]\n",
    "    for x in range(0,len(d4[\"name\"])):\n",
    "        if d4[\"name\"][x].lower()==theory.lower():\n",
    "            return d4['eco'][x],d4['name'][x],d4['pgn'][x]\n",
    "    for x in range(0,len(d5[\"name\"])):\n",
    "        if d5[\"name\"][x].lower()==theory.lower():\n",
    "            return d5['eco'][x],d5['name'][x],d5['pgn'][x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8409e25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def th_w_exp():\n",
    "    theory=input(\"You : \")\n",
    "    eco,name,pgn=find(theory)\n",
    "    return ch_comp_th(eco,name,pgn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269a18d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "def get_eval(fen):\n",
    "    stockfish.set_fen_position(fen)\n",
    "    x=stockfish.get_evaluation()\n",
    "    if x[\"type\"]==\"mate\":\n",
    "        return f\"Mate in {x['value']}\"\n",
    "    else:\n",
    "        return f\"{round((int(x['value'])**0.5) / 10.0, 1)} pawn advantage for {'white' if x['value'] > 0 else 'black'}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2761d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm_w_exp():\n",
    "    fen = input(\"You : \")\n",
    "    best_move = get_best_move(fen)\n",
    "    g = str(stockfish.will_move_be_a_capture(best_move)).split(\".\")[1]\n",
    "    if g==\"NO_CAPTURE\":\n",
    "        g=False\n",
    "    else:\n",
    "        g=True\n",
    "    evaluation=get_eval(fen)\n",
    "    p1_split = str(stockfish.get_what_is_on_square(best_move[:2])).split(\".\")\n",
    "    p2_split = str(stockfish.get_what_is_on_square(best_move[2:])).split(\".\")\n",
    "    p1 = p1_split[1] if len(p1_split) > 1 else p1_split[0]\n",
    "    p2 = p2_split[1] if len(p2_split) > 1 else p2_split[0]\n",
    "    if g:\n",
    "        type_of_move = f\"Capturing the {p2} with {p1}\"\n",
    "    elif \"e8g8\" in best_move and \"KING\" in p1:\n",
    "        type_of_move = f\"Castling with the {p1}\"\n",
    "    elif \"e8b8\" in best_move and \"KING\" in p1:\n",
    "        type_of_move = f\"Castling with the {p1}\"\n",
    "    elif \"e1g1\" in best_move and \"KING\" in p1:\n",
    "        type_of_move = f\"Castling with the {p1}\"\n",
    "    elif \"e1b1\" in best_move and \"KING\" in p1:\n",
    "        type_of_move = f\"Castling with the {p1}\"\n",
    "    else:\n",
    "        type_of_move = \"Move\"\n",
    "    print(\"Bot : \", ch_comp_bm_w_exp(fen, best_move, type_of_move,evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02ec4685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 19:21:12.501 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 19:21:12.553 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 19:21:12.553 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 19:21:12.553 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 19:21:12.588 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /opt/anaconda3/envs/BasicChatgpt/lib/python3.9/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-02-18 19:21:12.589 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 19:21:12.589 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 19:21:12.589 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 19:21:12.589 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-02-18 19:21:12.589 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from streamlit_chat import message\n",
    "\n",
    "message(\"My message\") \n",
    "message(\"Hello bot!\", is_user=True)  # align's the message to the right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a17be26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BasicChatgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
